{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import sqlalchemy\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from sqlalchemy import MetaData\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "#from sklearn.metrics import jaccard_similarity_score\n",
    "import jellyfish\n",
    "from time import time, ctime\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTED : Tue Feb  9 10:53:47 2021\n"
     ]
    }
   ],
   "source": [
    "print(\"STARTED : \"+ctime(start) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connection to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_uri = 'sqlite:////home/ubuntu/d3l/aura_pmi.db'\n",
    "#global engine \n",
    "engine = sqlalchemy.create_engine(db_uri, echo = False)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connection to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global graph \n",
    "graph = Graph(\"bolt://:7687\", auth=(\"neo4j\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = graph.run('MATCH ()-[t:COL_SIMILARITY]-() RETURN t')\n",
    "if (len(res.data())>0):\n",
    "    graph.run('MATCH ()-[t:COL_SIMILARITY]-() DELETE t')\n",
    "res = graph.run('MATCH ()-[t:PK_FK_LINK]-() RETURN t')\n",
    "if(len(res.data())>0):\n",
    "    graph.run('MATCH ()-[t:PK_FK_LINK]-() DELETE t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table_string_columns(table_id, neo_conn):\n",
    "    \n",
    "    res = neo_conn.run('''MATCH (t:Object:Table {identifier:\"'''+table_id+'''\"})<-[c:CONTAINS]-(col:Column) \n",
    "    WHERE col.type=\"STRING\" RETURN ID(col) AS id, col.name AS name, col.uniqueness AS uniqueness''')\n",
    "    result = []\n",
    "    #for item in res.data():\n",
    "    #    result.append(item)\n",
    "    return res.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard(vals1, vals2):\n",
    "    #print(len(vals1))\n",
    "    #print(len(vals2))\n",
    "    intersection = len(np.intersect1d(vals1, vals2))\n",
    "    union = float(len(np.union1d(vals1, vals2)))\n",
    "    jaccard = intersection/union\n",
    "    return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> Load list of all Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_table_ids  250\n"
     ]
    }
   ],
   "source": [
    "res = graph.run('MATCH (t:Object:Table) RETURN t.title AS title, t.identifier AS identifier') \n",
    "all_tables = [] \n",
    "all_table_ids = []\n",
    "for item in res.data():\n",
    "    all_tables.append(item['title'])\n",
    "    all_table_ids.append(item['identifier'])\n",
    "print(\"all_table_ids \", len(all_table_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_table_cols  250\n"
     ]
    }
   ],
   "source": [
    "all_table_cols = []\n",
    "for item in all_table_ids:\n",
    "    all_table_cols.append(load_table_string_columns(item, graph))\n",
    "print(\"all_table_cols \", len(all_table_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res = graph.run('''MATCH (t:Object:Table)<-[co:CONTAINS]-(c:Column) \n",
    "        WHERE c.type=\"STRING\" and  c.uniqueness<1 \n",
    "        RETURN ID(c) AS c_id, c.name AS c_name ,\n",
    "         t.title AS t_title, t.identifier AS t_identifier''') \n",
    "all_columns = res.data()\n",
    "print(\"all_columns \", len(all_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> Load list of tables that contain probable primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prim_table_ids  50\n"
     ]
    }
   ],
   "source": [
    "res = graph.run('MATCH (t:Object:Table)<-[co:CONTAINS]-(c:Column) \\\n",
    "                WHERE c.type=\"STRING\" AND c.uniqueness=1 \\\n",
    "                RETURN DISTINCT t.title AS title, t.identifier AS identifier')\n",
    "prim_tables = []\n",
    "prim_table_ids = []\n",
    "for item in res.data():\n",
    "    prim_tables.append(item['title'])\n",
    "    prim_table_ids.append(item['identifier'])\n",
    "print(\"prim_table_ids \", len(prim_table_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prim_table_cols  50\n"
     ]
    }
   ],
   "source": [
    "prim_table_cols = []\n",
    "for item in prim_table_ids:\n",
    "    prim_table_cols.append(load_table_string_columns(item, graph))\n",
    "print(\"prim_table_cols \", len(prim_table_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "res = graph.run('''MATCH (t:Object:Table)<-[co:CONTAINS]-(c:Column) \n",
    "        WHERE c.type=\"STRING\" and  c.uniqueness=1 \n",
    "        RETURN ID(c) AS c_id, c.name AS c_name ,\n",
    "         t.title AS t_title, t.identifier AS t_identifier''') \n",
    "prim_columns = res.data()\n",
    "print(\"prim_columns \", len(prim_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> Load columns by table id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_table_cols_similarities(table_l, id_l, rank, time_t, all_tables, all_table_ids, seuil=0.5, tolerance = 0.05):\n",
    "    count = 0\n",
    "    neo_conn = Graph(\"bolt://159.84.108.111:7687\", auth=(\"neo4j\", \"audal\"))\n",
    "    engine = sqlalchemy.create_engine('sqlite:////home/ubuntu/d3l/aura_pmi.db', echo = False)\n",
    "    #df_r = pd.read_sql_table(table_r, con=sqlite_conn)\n",
    "    #print(\"-----\"+table_l+\" -- \"+table_r)\n",
    "    print(\"START RANK : \", rank, \" TIME \", ctime(time()) )\n",
    "    #Load columns from left table (containing primary key)\n",
    "    try:\n",
    "        df_l = pd.read_sql_table(table_l, con=engine)\n",
    "        cols1 = load_table_string_columns(id_l, neo_conn)\n",
    "    except:\n",
    "        print(\"ERROR WITH LEFT TABLE \", table_l, \" : UNABLE TO LOAD LEFT COLUMNS\")\n",
    "        return 0\n",
    "            \n",
    "    #iterate right tables\n",
    "    for table_r, id_r in zip(all_tables, all_table_ids):\n",
    "        if(id_l != id_r):\n",
    "            \n",
    "            for col1 in cols1:\n",
    "                #second pruning condition : primary key is unique\n",
    "                ratio2 = col1['uniqueness']\n",
    "                keep2 = ratio2 >= 1-tolerance\n",
    "                if not keep2:\n",
    "                    continue #go to next column, when left is not unique\n",
    "                \n",
    "                try:\n",
    "                    cols2 = load_table_string_columns(id_r, graph)\n",
    "                    df_r = pd.read_sql_table(table_r, con=engine)\n",
    "                    for col2 in cols2:\n",
    "                        #first pruning condition\n",
    "                        ratio1 = col2['uniqueness']\n",
    "                        keep1 = ratio1 < 1\n",
    "                        if (not keep1):\n",
    "                            continue #go to next when right column is unique,\n",
    "\n",
    "                        #third pruning condition\n",
    "                        #(Always verified, all ccolumns non numeric)\n",
    "\n",
    "                        #Similarity check\n",
    "                        sim_val = compute_jaccard(df_l[col1['name']].dropna(), df_r[col2['name']].dropna())\n",
    "                        if sim_val >= seuil: #continue if similarity is significant\n",
    "\n",
    "                            #fourth pruning condition: Containement check\n",
    "                            containment_prop = df_r[col2['name']].dropna().isin(df_l[col1['name']].dropna()).value_counts(normalize=True, sort=True, dropna=True).to_dict().get(True)\n",
    "                            if ((containment_prop != None) and (containment_prop >= 1-tolerance)):\n",
    "                                #Make scores \n",
    "                                score1 = jellyfish.jaro_winkler_similarity(col1['name'], col2['name'])\n",
    "                                #Column-table name\n",
    "                                score2 = jellyfish.jaro_winkler_similarity(col2['name'], table_l)\n",
    "                                #Content sim\n",
    "                                score3 = sim_val \n",
    "                                score = np.mean([score1, score2, score3])\n",
    "\n",
    "                                #insert in Neo4J\n",
    "                                res = neo_conn.run(''' MATCH (c1:Column), (c2:Column) \n",
    "                                    WHERE ID(c1) = '''+str(col1['id'])+''' AND ID(c2) = '''+str(col2['id'])+'''\n",
    "                                    CREATE (c1)<-[l:PK_FK_LINK {value:'''+str(score)+'''}]-(c2)''')\n",
    "                                count = count+1\n",
    "                except: \n",
    "                    print(\"ERROR WITH RIGHT TABLE \", table_r, \" : UNABLE TO LOAD RIGHT COLUMNS\")\n",
    "                    continue\n",
    "            \n",
    "    \n",
    "    print(\"FINISH RANK : \", rank, \" TIME \", ctime(time()), \" ELAPSED SINCE START : \", str((time()-time_t)/60), \" MINUTES \" )\n",
    "    \n",
    "    return count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_table_cols_similarities(tables[100],tables[0],table_ids[100], table_ids[0], neo_conn=graph, sqlite_conn=engine, seuil=0.5, tolerance = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_table_cols_similarities2(table_l, id_l, cols1, rank, time_t, all_tables, all_table_ids, liste_cols2, seuil=0.5, tolerance = 0.05):\n",
    "    count = 0\n",
    "    queries = []\n",
    "    #neo_conn = Graph(\"bolt://159.84.108.111:7687\", auth=(\"neo4j\", \"audal\"))\n",
    "    engine = sqlalchemy.create_engine('sqlite:////home/ubuntu/d3l/aura_pmi.db', echo = False)\n",
    "    #df_r = pd.read_sql_table(table_r, con=sqlite_conn)\n",
    "    #print(\"-----\"+table_l+\" -- \"+table_r)\n",
    "    print(\"START RANK : \", rank, \" TIME \", ctime(time()) )\n",
    "    #Load columns from left table (containing primary key)\n",
    "    try:\n",
    "        df_l = pd.read_sql_table(table_l, con=engine)\n",
    "        #cols1 = load_table_string_columns(id_l, neo_conn)\n",
    "    except:\n",
    "        print(\"ERROR WITH LEFT TABLE \", table_l, \" : UNABLE TO LOAD LEFT COLUMNS\")\n",
    "        return 0\n",
    "            \n",
    "    #iterate right tables\n",
    "    for table_r, id_r, cols2 in zip(all_tables, all_table_ids, liste_cols2):\n",
    "        if(id_l != id_r):\n",
    "            \n",
    "            for col1 in cols1:\n",
    "                #second pruning condition : primary key is unique\n",
    "                ratio2 = col1['uniqueness']\n",
    "                keep2 = ratio2 >= 1-tolerance\n",
    "                if not keep2:\n",
    "                    continue #go to next column, when left is not unique\n",
    "                \n",
    "                try:\n",
    "                    #cols2 = load_table_string_columns(id_r, graph)\n",
    "                    df_r = pd.read_sql_table(table_r, con=engine)\n",
    "                    for col2 in cols2:\n",
    "                        #first pruning condition\n",
    "                        ratio1 = col2['uniqueness']\n",
    "                        keep1 = ratio1 < 1\n",
    "                        if (not keep1):\n",
    "                            continue #go to next when right column is unique,\n",
    "\n",
    "                        #third pruning condition\n",
    "                        #(Always verified, all ccolumns non numeric)\n",
    "\n",
    "                        #Similarity check\n",
    "                        sim_val = compute_jaccard(df_l[col1['name']].dropna(), df_r[col2['name']].dropna())\n",
    "                        if sim_val >= seuil: #continue if similarity is significant\n",
    "\n",
    "                            #fourth pruning condition: Containement check\n",
    "                            containment_prop = df_r[col2['name']].dropna().isin(df_l[col1['name']].dropna()).value_counts(normalize=True, sort=True, dropna=True).to_dict().get(True)\n",
    "                            if ((containment_prop != None) and (containment_prop >= 1-tolerance)):\n",
    "                                #Make scores \n",
    "                                score1 = jellyfish.jaro_winkler_similarity(col1['name'], col2['name'])\n",
    "                                #Column-table name\n",
    "                                score2 = jellyfish.jaro_winkler_similarity(col2['name'], table_l)\n",
    "                                #Content sim\n",
    "                                score3 = sim_val \n",
    "                                score = np.mean([score1, score2, score3])\n",
    "\n",
    "                                #insert in Neo4J\n",
    "                                #res = neo_conn.run(''' MATCH (c1:Column), (c2:Column) \n",
    "                                #    WHERE ID(c1) = '''+str(col1['id'])+''' AND ID(c2) = '''+str(col2['id'])+'''\n",
    "                                #    CREATE (c1)<-[l:PK_FK_LINK {value:'''+str(score)+'''}]-(c2)''')\n",
    "                                count = count+1\n",
    "                                queries.append(''' MATCH (c1:Column), (c2:Column) WHERE ID(c1) = '''+str(col1['id'])+''' AND ID(c2) = '''+str(col2['id'])+''' CREATE (c1)<-[l:PK_FK_LINK {value:'''+str(score)+'''}]-(c2)''')\n",
    "                except Exception as e:\n",
    "                    print(\"ERROR WITH RIGHT TABLE \", table_r, \" : UNABLE TO LOAD RIGHT COLUMNS\")\n",
    "                    print(e)\n",
    "                    continue\n",
    "            \n",
    "    \n",
    "    print(\"FINISH RANK : \", rank, \" TIME \", ctime(time()), \" ELAPSED SINCE START : \", str((time()-time_t)/60), \" MINUTES \" )\n",
    "    \n",
    "    return queries\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identification of PK/FK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identification of PK/FK STARTING... Tue Feb  9 10:53:53 2021\n"
     ]
    }
   ],
   "source": [
    "print(\"Identification of PK/FK STARTING... \"+ctime(time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time_t = time()\n",
    "Parallel(n_jobs=5)(delayed(compute_table_cols_similarities2)\\\n",
    "                   (table_l, id_l, rank, time_t, all_tables, all_table_ids) \\\n",
    "                           for table_l, id_l, rank in zip(prim_tables, prim_table_ids, range(len(prim_tables))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_t = time()\n",
    "ranks = range(len(prim_tables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=-2)(delayed(compute_table_cols_similarities2)\\\n",
    "                   (table_l, id_l, prim_table_col, rank, time_t, all_tables, all_table_ids, all_table_cols) \\\n",
    "                           for table_l, id_l, prim_table_col, rank in zip(prim_tables, prim_table_ids, prim_table_cols, ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  OF  1  CONNECTIONS CREATED\n"
     ]
    }
   ],
   "source": [
    "queries = [item for sublist in results for item in sublist]\n",
    "ok=0\n",
    "for query in queries:\n",
    "    try:\n",
    "        res= graph.run(query)\n",
    "        ok=ok+1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "print(ok, \" OF \", len(queries), \" CONNECTIONS CREATED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "STARTED : Tue Feb  9 10:53:47 2021\n",
      "END : Tue Feb  9 11:02:59 2021\n",
      "TIME ELAPSED:9.208821845054626 MINUTES\n"
     ]
    }
   ],
   "source": [
    "done = time()\n",
    "elapsed = done - start\n",
    "print(\"*\"*20)\n",
    "print(\"STARTED : \"+ctime(start) )\n",
    "print(\"END : \"+ctime(done) )\n",
    "print(\"TIME ELAPSED:\" + str(elapsed/60) + \" MINUTES\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def test(n, rank):\n",
    "    res= 1\n",
    "    temp = n\n",
    "    while temp > 1:\n",
    "        res = res\n",
    "        temp = temp-1\n",
    "    print(\"RANK : \", rank, \" TIME: \", ctime(time()))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel(n_jobs=5)(delayed(test)\\\n",
    "                   (i, j) \\\n",
    "                           for j, i in zip(range(100), np.repeat(500000, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
