{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import sqlalchemy\n",
    "from sqlalchemy import MetaData\n",
    "from py2neo import Graph, Node, Relationship\n",
    "from time import time, sleep, ctime\n",
    "from baseconv import base64, base16\n",
    "from elasticsearch import Elasticsearch\n",
    "import glob\n",
    "import os\n",
    "import tika\n",
    "from tika import detector\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connection to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"\", auth=(\"neo4j\", \"\"))\n",
    "#RÃ©init Neo4j DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph.run('MATCH (r1:Table)-[t:REPRESENTATION]-(r2:Table) DELETE t')\n",
    "#graph.run('MATCH (x:Table)-[c:CONTAINS]-(y:Column) DELETE c')\n",
    "res1 = graph.run('MATCH (n:Table)  RETURN n')\n",
    "if(len(res1.data())>0): #existing tables\n",
    "    graph.run('MATCH (t:Table) DETACH DELETE t')\n",
    "res2 = graph.run('MATCH (n:Column)  RETURN n')\n",
    "if(len(res2.data())>0): #existing tables\n",
    "    graph.run('MATCH (c:Column) DETACH DELETE c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connection to SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_uri = 'sqlite:////home/ubuntu/d3l/aura_pmi.db'\n",
    "engine = sqlalchemy.create_engine(db_uri, echo = False)\n",
    "connection = engine.connect()\n",
    "#connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all\n",
    "meta = MetaData()\n",
    "meta.reflect(engine)\n",
    "meta.drop_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Connection to ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch([{'host':'','port':9200}])\n",
    "es.indices.delete(index='table_index', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'table_index'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "  \"mappings\": {\n",
    "     #\"_doc\": { \n",
    "        \"date_detection\": False, \n",
    "        \"properties\": { \n",
    "           \"keywords\": { \"type\": \"keyword\"  }, \n",
    "\n",
    "         }\n",
    "      }\n",
    "   #}\n",
    " }\n",
    "es.indices.create(index='table_index', ignore=[400, 404], body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_table(table, sqlite_conn):\n",
    "    inspector = sqlalchemy.inspect(sqlite_conn)\n",
    "    columns = []\n",
    "    for column in inspector.get_columns(table):\n",
    "        columns.append(str(column['name']))\n",
    "    count_result = sqlite_conn.execute(\"SELECT COUNT(*) FROM \"+str(table)+\" ;\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = \"/home/ubuntu/d3l/data/\"\n",
    "table_dfs = []\n",
    "table_paths = []\n",
    "\n",
    "for i, file in enumerate(glob.glob(files_path+\"/*.csv\")):\n",
    "    if i < limit:\n",
    "        table_paths.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(table_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> Generating identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ids = []\n",
    "for table_path in table_paths:\n",
    "    identifier = base16.encode(int(round(time()*1000)))\n",
    "    table_ids.append(identifier)\n",
    "    sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table_nodes(table_df, file_path, table_id, neo_conn, db_path):\n",
    "    #Object\n",
    "    basic_metadata = {}\n",
    "    table_id = '''\"'''+table_id+'''\"'''\n",
    "    basic_metadata['identifier'] = table_id\n",
    "    basic_metadata['nbRow'] = table_df.shape[0]\n",
    "    basic_metadata['nbCol'] = table_df.shape[1]\n",
    "    basic_metadata['title'] = '''\"'''+table_df.name+'''\"'''\n",
    "    \n",
    "    neo_conn.run('''CREATE (r:Object:Table '''+str(basic_metadata).replace(\"'\", \"\")+''') RETURN r''')\n",
    "    \n",
    "    #Raw representation\n",
    "    neo_conn.run('''CREATE (r:Raw:Table { identifier: '''+str(table_id)+''', \n",
    "            storageType:\"file_system\", path:\"'''+str(file_path.replace(\"\\\\\",\"/\"))+'''\"}) RETURN r''')\n",
    "    neo_conn.run('''MATCH (o:Object { identifier: '''+str(table_id)+'''}),\n",
    "              (r:Raw { identifier: '''+str(table_id)+'''}) \n",
    "              CREATE (o)-[l:REPRESENTATION]->(r) ''')\n",
    "    \n",
    "    #Refined representation\n",
    "    neo_conn.run('''CREATE (r:Refined:Table { identifier: '''+str(basic_metadata[\"identifier\"])+''', \n",
    "            storageType:\"sqlite\", path:\"'''+str(db_path)+'''\"}) RETURN r''')\n",
    "    neo_conn.run('''MATCH (o:Object { identifier: '''+str(basic_metadata[\"identifier\"])+'''}),\n",
    "              (r:Refined { identifier: '''+str(table_id)+'''}) \n",
    "              CREATE (o)-[l:REPRESENTATION]->(r) ''')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_columns(df, identifier, neo_conn):\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if len(df[col].dropna().tolist())>0:\n",
    "            col_properties = {}\n",
    "            col_type = str(df.infer_objects().dtypes[col])\n",
    "            col_properties['uniqueness'] = len(df[col].value_counts())/len(df)\n",
    "            col_properties['name'] = '''\"'''+col+'''\"'''\n",
    "            if col_type == 'object': #String data\n",
    "                col_properties['type'] = '''\"STRING\"'''\n",
    "                col_properties['mode'] = '''\"'''+re.sub(r'(?u)[^-\\w.]', '', df.mode()[col][0])+'''\"'''\n",
    "            elif col_type == 'int64':\n",
    "                col_properties['type'] = '''\"INTEGER\"'''\n",
    "                col_properties['mean'] = np.mean(df[col].dropna())\n",
    "            elif col_type == 'float64':\n",
    "                col_properties['type'] = '''\"DECIMAL\"'''\n",
    "                col_properties['mean'] = np.mean(df[col].dropna())\n",
    "            #Create column and Associate column to table object\n",
    "            neo_conn.run('''CREATE (c:Column '''+str(col_properties).replace(\"'\", \"\")+''')\n",
    "                        WITH c MATCH (o:Object {identifier:\"'''+identifier+'''\" }) \n",
    "                        CREATE (o)<-[l:CONTAINS]-(c) RETURN o, c ''' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2- Indexing and insertion into SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_date_parser = lambda x: datetime.strptime(x, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0\n",
      "TIME : Thu Jan 28 15:47:45 2021\n",
      "----- 100\n",
      "TIME : Thu Jan 28 15:49:34 2021\n",
      "----- 200\n",
      "TIME : Thu Jan 28 15:51:26 2021\n",
      "----- 300\n",
      "TIME : Thu Jan 28 15:53:18 2021\n",
      "----- 400\n",
      "TIME : Thu Jan 28 15:55:05 2021\n",
      "----- 500\n",
      "TIME : Thu Jan 28 15:56:54 2021\n",
      "----- 600\n",
      "TIME : Thu Jan 28 15:58:46 2021\n",
      "----- 700\n",
      "TIME : Thu Jan 28 16:00:30 2021\n",
      "----- 800\n",
      "TIME : Thu Jan 28 16:02:27 2021\n",
      "----- 900\n",
      "TIME : Thu Jan 28 16:04:29 2021\n",
      "----- 1000\n",
      "TIME : Thu Jan 28 16:06:15 2021\n",
      "----- 1100\n",
      "TIME : Thu Jan 28 16:08:03 2021\n",
      "----- 1200\n",
      "TIME : Thu Jan 28 16:09:51 2021\n",
      "----- 1300\n",
      "TIME : Thu Jan 28 16:11:38 2021\n",
      "----- 1400\n",
      "TIME : Thu Jan 28 16:13:41 2021\n",
      "----- 1500\n",
      "TIME : Thu Jan 28 16:15:30 2021\n",
      "----- 1600\n",
      "TIME : Thu Jan 28 16:17:33 2021\n",
      "----- 1700\n",
      "TIME : Thu Jan 28 16:19:31 2021\n",
      "----- 1800\n",
      "TIME : Thu Jan 28 16:21:30 2021\n",
      "----- 1900\n",
      "TIME : Thu Jan 28 16:23:33 2021\n",
      "----- 2000\n",
      "TIME : Thu Jan 28 16:25:37 2021\n",
      "----- 2100\n",
      "TIME : Thu Jan 28 16:27:37 2021\n",
      "----- 2200\n",
      "TIME : Thu Jan 28 16:29:30 2021\n",
      "----- 2300\n",
      "TIME : Thu Jan 28 16:31:47 2021\n",
      "----- 2400\n",
      "TIME : Thu Jan 28 16:33:52 2021\n",
      "----- 2500\n",
      "TIME : Thu Jan 28 16:35:57 2021\n",
      "----- 2600\n",
      "TIME : Thu Jan 28 16:37:53 2021\n",
      "----- 2700\n",
      "TIME : Thu Jan 28 16:40:00 2021\n",
      "----- 2800\n",
      "TIME : Thu Jan 28 16:41:55 2021\n",
      "----- 2900\n",
      "TIME : Thu Jan 28 16:44:09 2021\n",
      "----- 3000\n",
      "TIME : Thu Jan 28 16:45:59 2021\n",
      "----- 3100\n",
      "TIME : Thu Jan 28 16:47:55 2021\n",
      "----- 3200\n",
      "TIME : Thu Jan 28 16:49:49 2021\n",
      "----- 3300\n",
      "TIME : Thu Jan 28 16:51:50 2021\n",
      "----- 3400\n",
      "TIME : Thu Jan 28 16:53:55 2021\n",
      "----- 3500\n",
      "TIME : Thu Jan 28 16:55:59 2021\n",
      "----- 3600\n",
      "TIME : Thu Jan 28 16:58:13 2021\n",
      "----- 3700\n",
      "TIME : Thu Jan 28 17:00:13 2021\n",
      "----- 3800\n",
      "TIME : Thu Jan 28 17:02:19 2021\n",
      "----- 3900\n",
      "TIME : Thu Jan 28 17:04:18 2021\n",
      "----- 4000\n",
      "TIME : Thu Jan 28 17:06:25 2021\n",
      "----- 4100\n",
      "TIME : Thu Jan 28 17:08:22 2021\n",
      "----- 4200\n",
      "TIME : Thu Jan 28 17:10:32 2021\n",
      "----- 4300\n",
      "TIME : Thu Jan 28 17:12:46 2021\n",
      "----- 4400\n",
      "TIME : Thu Jan 28 17:14:56 2021\n",
      "----- 4500\n",
      "TIME : Thu Jan 28 17:17:06 2021\n",
      "----- 4600\n",
      "TIME : Thu Jan 28 17:19:17 2021\n",
      "----- 4700\n",
      "TIME : Thu Jan 28 17:21:20 2021\n",
      "----- 4800\n",
      "TIME : Thu Jan 28 17:23:18 2021\n",
      "----- 4900\n",
      "TIME : Thu Jan 28 17:25:58 2021\n"
     ]
    }
   ],
   "source": [
    "for i, table_path in enumerate(table_paths):\n",
    "    df = pd.read_csv(table_path, sep=',')\n",
    "    df.name = os.path.basename(table_path).split('.')[0] #omit extension\n",
    "    identifier = table_ids[i]\n",
    "    #Insert into ES\n",
    "    content = {}\n",
    "    content['identifier'] = identifier\n",
    "    terms = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        #col_type = df.infer_objects().dtypes[col]\n",
    "        col_type = df.dtypes[col]\n",
    "        #print(df.dtypes)\n",
    "        if col_type == 'object': #Insert if non numeric\n",
    "            temp = df[col].dropna().unique()\n",
    "            col_values = [term for term in temp if len(re.sub(\"[^a-zA-Z]\", \"\", term))>0]\n",
    "            terms.extend(col_values)\n",
    "    \n",
    "    content['keywords'] = terms       \n",
    "    res = es.index(index='table_index',doc_type='_doc',body=content)\n",
    "    #insert into SQLite\n",
    "    \n",
    "    df.to_sql(name=df.name, con=engine, if_exists='replace', index=False)\n",
    "    #Insert into Neo4J\n",
    "    generate_table_nodes(df, table_path, identifier, graph, db_uri)\n",
    "    generate_columns(df, identifier, graph)\n",
    "    if(i % 100 == 0):\n",
    "        print(\"-\"*5+' '+str(i))\n",
    "        print(\"TIME : \"+ctime(time()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3- Insertion in Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### --> Generate Table Nodes and Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "STARTED : Thu Jan 28 15:31:00 2021\n",
      "END : Thu Jan 28 17:28:21 2021\n",
      "TIME ELAPSED:117.34288415908813 MINUTES\n"
     ]
    }
   ],
   "source": [
    "done = time()\n",
    "elapsed = done - start\n",
    "print(\"*\"*20)\n",
    "print(\"STARTED : \"+ctime(start) )\n",
    "print(\"END : \"+ctime(done) )\n",
    "print(\"TIME ELAPSED:\" + str(elapsed/60) + \" MINUTES\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
